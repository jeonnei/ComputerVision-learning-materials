{"cells":[{"cell_type":"markdown","metadata":{"id":"nmq_ohyPB_im"},"source":["# 답안 작성 방법\n","\n","아래 이미지에서 \"더블클릭 또는 Enter키를 눌러 수정\"을 누르신후 해당 창에 답을 적으시면 됩니다.\n","\n","![image](https://github.com/user-attachments/assets/2aa2ff05-fb0e-4f00-a121-78afeaad4f09)\n","\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"JiAFUXF2DadY"},"source":["# 08차시 과제"]},{"cell_type":"markdown","metadata":{"id":"EAOcilHvRFs5"},"source":["### Q1. 머신러닝에서 분류(classification) 알고리즘에는 어떠한 것들이 5개 이상 서술하라."]},{"cell_type":"markdown","metadata":{"id":"tY-NkNYRRFs5"},"source":["1. 로지스틱 회귀 (Logistic Regression)\n","2. 서포트 벡터 머신 (Support Vector Machine, SVM)\n","3. 결정 트리 (Decision Tree)\n","4. 랜덤 포레스트 (Random Forest)\n","5. 나이브 베이즈 (Naive Bayes)"]},{"cell_type":"markdown","metadata":{"id":"n-hnLxCqRFs5"},"source":["### Q2. 머신러닝에서 회귀(regression) 알고리즘에는 어떠한 것들이 5개 이상 서술하라."]},{"cell_type":"markdown","metadata":{"id":"qLv798NhRFs5"},"source":["선형 회귀 (Linear Regression)\n","다항 회귀 (Polynomial Regression)\n","랜덤 포레스트 회귀(Random Forest Regression)\n","결정 트리 회귀(Decision Tree Regression)\n","서포트 벡터 회귀(Support Vector Regression)"]},{"cell_type":"markdown","metadata":{"id":"HNpSVLsNRFs5"},"source":["### Q3. SVM에서 마진(margin)이 무엇이고 어떠한 역할을 하는지 서술하라."]},{"cell_type":"markdown","metadata":{"id":"w19s5n4ORFs6"},"source":["마진(margin)은 결정 경계와 가장 가까운 데이터 포인트 사이의 거리로, 마진을 최대화하면 모델이 더 안정적이고 과적합을 방지할 수 있습니다. 마진이 넓을수록 일반화 성능이 향상됩니다."]},{"cell_type":"markdown","metadata":{"id":"lp1kgDYiRFs6"},"source":["### Q4.  이상치(Outlier)가 무엇인지 서술하라."]},{"cell_type":"markdown","metadata":{"id":"6qt27M-7RFs6"},"source":["이상치(Outlier)는 데이터 세트에서 다른 값들과 크게 다른 값으로, 분석 결과를 왜곡하거나 모델 성능에 영향을 줄 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"fhYY3Z_uRFs6"},"source":["### Q5. Tensorflow에서 모델을 컴파일하는 함수가 무엇인지 적어라."]},{"cell_type":"markdown","metadata":{"id":"VZlvdlDvRFs6"},"source":["\n","TensorFlow에서 모델을 컴파일하는 함수는 model.compile()입니다. 이 함수는 모델의 학습을 위해 옵티마이저, 손실 함수, 그리고 평가 지표를 설정합니다"]},{"cell_type":"markdown","metadata":{"id":"0B3DPavgRFs6"},"source":["### Q6. Tensorflow에서 모델을 학습시키는 함수가 무엇인지, 그리고 그 함수의 인자로는 무엇이 필요한지 적어라."]},{"cell_type":"markdown","metadata":{"id":"Y3DUhh7tRFs6"},"source":["TensorFlow에서 모델을 학습시키는 함수는 model.fit()\n","\n","x: 입력 데이터.\n","\n","y: 출력(레이블) 데이터.\n","\n","epochs: 학습을 반복할 횟수.\n","\n","batch_size: 한 번의 학습에 사용될 데이터 샘플의 수.\n","\n","validation_data: 검증 데이터 ."]},{"cell_type":"markdown","metadata":{"id":"fmfGIODiRFs6"},"source":["### Q7. 아래 코드는 TensorFlow를 사용하여 붓꽃(Iris) 데이터를 k-means 알고리즘으로 클러스터링하는 코드이다. 코드에 주석을 추가로 달아라.\n","\n","* 단 시각화 코드에는 주석을 달지 않아도 된다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwoqpwYORFs7"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_iris\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","\n","# 붓꽃 데이터 로드\n","iris = load_iris()\n","data = iris.data\n","\n","# 데이터 정규화 (스케일링)\n","scaler = StandardScaler()\n","data = scaler.fit_transform(data)\n","\n","# k-means 매개변수\n","k = 3                     # 클러스터의 수\n","max_iterations = 100      # 최대 반복 횟수\n","tolerance = 1e-4          # 클러스터 중심 이동 허용 오차\n","\n","# 초기 클러스터 중심을 랜덤하게 선택\n","centroids = tf.Variable(data[np.random.choice(data.shape[0], k, replace=False)])\n","\n","# k-means 알고리즘\n","for iteration in range(max_iterations):\n","    # 각 데이터 포인트와 클러스터 중심 사이의 거리 계산\n","    distances = tf.norm(data[:, np.newaxis] - centroids, axis=2)\n","\n","    # 각 데이터 포인트를 가장 가까운 중심에 할당\n","    closest_centroids = tf.argmin(distances, axis=1)\n","\n","    new_centroids = []\n","    for c in range(k):\n","        # 현재 클러스터에 할당된 데이터 포인트 선택\n","        assigned_points = tf.gather(data, tf.where(closest_centroids == c))\n","        assigned_points = tf.squeeze(assigned_points, axis=1)\n","        new_centroids.append(tf.reduce_mean(assigned_points, axis=0))\n","\n","    new_centroids = tf.stack(new_centroids)   # 새로운 클러스터 중심으로 업데이트\n","\n","    centroid_shift = tf.reduce_sum(tf.abs(new_centroids - centroids)) # 중심 이동 거리 계산\n","\n","    centroids.assign(new_centroids) # 기존 중심을 새로운 중심으로 업데이\n","    # 중심 이동이 허용 오차보다 작으면 수렴했다고 판단하고 반복 중지\n","    if centroid_shift < tolerance:\n","        print(f'수렴되었습니다. 반복 횟수: {iteration}')\n","        break\n","# 최종 클러스터 중심 및 데이터 포인트 할당 결과 출력\n","print(f'최종 중심: \\n{centroids.numpy()}')\n","print(f'클러스터 할당: \\n{closest_centroids.numpy()}')\n","\n","\n","# 시각화\n","\n","# 2D로 시각화를 위해 PCA를 사용하여 데이터 차원 축소\n","pca = PCA(n_components=2)\n","reduced_data = pca.fit_transform(data)\n","reduced_centroids = pca.transform(centroids.numpy())\n","\n","plt.figure(figsize=(8, 6))\n","for i in range(k):\n","    cluster_points = reduced_data[closest_centroids.numpy() == i]\n","    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'cluster {i + 1}')\n","\n","plt.scatter(reduced_centroids[:, 0], reduced_centroids[:, 1], color='red', marker='x', s=100, label='center')\n","plt.title('K-means clustering results of Iris data')\n","plt.xlabel('PCA Component 1')\n","plt.ylabel('PCA Component 2')\n","plt.legend()\n","plt.show()\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}