{"cells":[{"cell_type":"markdown","metadata":{"id":"nmq_ohyPB_im"},"source":["# 답안 작성 방법\n","\n","아래 이미지에서 \"더블클릭 또는 Enter키를 눌러 수정\"을 누르신후 해당 창에 답을 적으시면 됩니다.\n","\n","![image](https://github.com/user-attachments/assets/2aa2ff05-fb0e-4f00-a121-78afeaad4f09)\n","\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"JiAFUXF2DadY"},"source":["# 05차시 과제"]},{"cell_type":"markdown","metadata":{"id":"6B1L4wa1eD3D"},"source":["### Logistic Regression이 무엇인지 서술하시오."]},{"cell_type":"markdown","metadata":{"id":"4nJD7yUmeD3D"},"source":["이진 분류를 수행하는 모델은 시그모이드 함수를 사용하여 입력값을 확률로 변환합니다. 이 확률을 기반으로 데이터를 두 개의 클래스 중 하나로 분류합니다."]},{"cell_type":"markdown","metadata":{"id":"NJ5ggcDKeD3E"},"source":["### Logistic Regression을 사용할 수 있는 사례를 5가지만 서술하시오."]},{"cell_type":"markdown","metadata":{"id":"IfkY8YJdeD3E"},"source":["1. 스팸 이메일 필터링\n","\n","2. 질병 진단\n","\n","3. 고객 이탈 예측\n","\n","4. 광고 클릭 예측\n","\n","5. 은행 대출 승인"]},{"cell_type":"markdown","metadata":{"id":"TdM07rT9eD3E"},"source":["### 제시된 코드에 주석을 작성하고 조건에 맞추어 빈칸(***)를 채워라.\n","\n","**조건**\n","\n","1. Optimizer는 Adam을 사용하라\n","2. learning rate는 0.001을 사용하라\n","3. loss function은 MSE를 사용하라.\n","4. 에포크는 100으로 설정하라."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"t0a-QeOKeD3E","executionInfo":{"status":"ok","timestamp":1724336772444,"user_tz":-540,"elapsed":480,"user":{"displayName":"전성현","userId":"03409279143485008331"}}},"outputs":[],"source":["import torch\n","\n","model = torch.nn.Linear(2, 1)\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = torch.nn.MSELoss()\n","\n","x_data = torch.Tensor([[1.0, 1.5], [2.0, 3.0], [2.0, 4.0]])\n","y_data = torch.Tensor([[2.0], [4.0], [6.0]])\n","\n","for epoch in range(100):\n","    y_pred = model(x_data)\n","\n","    loss = criterion(y_pred, y_data)\n","\n","    optim.zero_grad()\n","    loss.backward()\n","    optim.step()"]},{"cell_type":"markdown","metadata":{"id":"srphXgjgeD3F"},"source":["### 역전파(Back-propagation)이 무엇인지 서술하시오."]},{"cell_type":"markdown","metadata":{"id":"uLZoBNKkeD3F"},"source":["역전파는 순전파를 통해 계산된 출력의 오차를 바탕으로 오차를 역으로 전파하여 각 층의 가중치와 편향을 조정하는 과정입니다."]},{"cell_type":"markdown","metadata":{"id":"CtGb29MCeD3G"},"source":["### 아래 제공된 수식은 sigmoid 함수이다. z값이 양의 무한대로 발산할때와 음의 무한대로 발산할 때 각각 sigmoid 값이 어떻게 변하는지 서술하라.\n","\n","\n","$$\n","\n","\\sigma(z) = {1 \\over 1+e^{-z}}\n","\n","$$\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NCiMWOKPeD3G"},"source":["입력이 양의 무한대에 가까워지면 시그모이드 함수의 출력은 1에 수렴하고, 입력이 음의 무한대에 가까워지면 출력은 0에 수렴합니다."]},{"cell_type":"markdown","metadata":{"id":"hLzloa8ueD3G"},"source":["### Sigmoid 함수의 입력값(z)이 양의 무한대로 발산하거나 음의 무한대로 발산하는 경우 인공지능 모델의 학습에 어떠한 영향을 미치는지 서술하라.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"N5NUkiOdeD3G"},"source":["그라디언트가 너무 작아져서 학습이 제대로 이루어지지 않는 문제가 발생한다."]},{"cell_type":"markdown","metadata":{"id":"PgGWaKP8eD3G"},"source":["### 아래 제공된 수식은 cross entropy loss에 관한 수식이다. y = [1, 1, 0, 0]이고  $\\hat{y}$은 [1.0, 0.25, 0.875, 0.0]일 때의 loss 값을 구하라.\n","\n","* 아래 수식에서 log의 밑은 2라고 가정한다.\n","$$\n","    loss = - {1 \\over N} log \\hat{y} \\sum_{n=1}^{N}y_n log\\hat{y}_n + (1- y_n)log (1-\\hat{y}_n)\n","$$"]},{"cell_type":"markdown","metadata":{"id":"ltLfgzpReD3G"},"source":["간단요약:\n","loss = −1/4[0+2+3+0]\n","\n","loss = − 5/4\n","\n","loss = 1.25"]},{"cell_type":"markdown","metadata":{"id":"FnbZPNUyeD3G"},"source":["### 아래 제공된 두 행렬식의 곱셈 결과를 구하라.\n","\n","$$\n","\n","A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\n","\\qquad\n","B = \\begin{bmatrix} 4 & 3 \\\\ 2 & 1 \\end{bmatrix}\n","$$\n","\n","$$\n","A \\times B = ?\n","$$"]},{"cell_type":"markdown","metadata":{"id":"QOSUKu66eD3G"},"source":["정답 \\begin{bmatrix} 8 & 5 \\\\ 20 & 13 \\end{bmatrix}"]},{"cell_type":"markdown","metadata":{"id":"HjdswVS7eD3H"},"source":["### 아래 코드의 output을 확인한 후 행렬곱과 완전 연결 신경망(fully-connected layer)의 관계에 대해 서술하라."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJ4V9fQ7eD3H","executionInfo":{"status":"ok","timestamp":1724337519991,"user_tz":-540,"elapsed":347,"user":{"displayName":"전성현","userId":"03409279143485008331"}},"outputId":"624133df-7bd7-4ed3-fc5d-300559ddb166"},"outputs":[{"output_type":"stream","name":"stdout","text":["A와 B의 행렬 곱 :  tensor([[ 9.,  5.],\n","        [25., 14.]])\n","A를 linear layer W에 통과시킨 output 값 tensor([[ 9.,  5.],\n","        [25., 14.]], grad_fn=<MmBackward0>)\n"]}],"source":["import torch\n","\n","A = torch.Tensor([[1, 2], [3, 5]])\n","B = torch.Tensor([[5, 3], [2, 1]])\n","print(\"A와 B의 행렬 곱 : \", torch.matmul(A, B))\n","\n","W = linear = torch.nn.Linear(2, 2, bias=False)\n","W.weight = torch.nn.Parameter(B.T)\n","print(\"A를 linear layer W에 통과시킨 output 값\", W(A))"]},{"cell_type":"markdown","source":["완전 연결 신경망은 행렬 곱셈을 통해 입력 데이터와 가중치를 결합하여 각 뉴런의 출력을 계산합니다."],"metadata":{"id":"FZTOBKm4h1Sj"}},{"cell_type":"markdown","metadata":{"id":"L1zaY9NzeD3H"},"source":["### BatchSize와 Epoch이 무엇인지 각각 서술하시오."]},{"cell_type":"markdown","metadata":{"id":"bqJ184hOeD3H"},"source":["배치 크기(Batch Size)는 한 번의 가중치 업데이트에서 처리되는 데이터 샘플의 수를 나타내며, 에포크(Epoch)는 전체 학습 데이터셋이 모델을 통해 완전히 한 번 학습되는 횟수를 의미합니다."]},{"cell_type":"markdown","metadata":{"id":"AI_mgLsNeD3H"},"source":["### 제공된 조건에 맞추어 아래 코드의 빈칸(***)을 채우고 코드가 오류없이 돌아가는지 확인하시오.\n","\n","**조건**\n","* 모델은 4개의 linear layer로 구성되어 있다.\n","* 각 linear layer의 input과 output은 다음과 같다.\n","    * linear1\n","        * input: 1\n","        * output: 3\n","    * linear2\n","        * input: 3\n","        * output: 5\n","    * linear3\n","        * input: 5\n","        * output: 5\n","    * linear4\n","        * input: 5\n","        * output: 1\n","\n","* model의 layer 구성은 다음과 같다.\n","    * linear1 --> relu --> linear2 --> relu --> linear3 --> relu --> linear4"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5Swe3abeD3H","executionInfo":{"status":"ok","timestamp":1724337675214,"user_tz":-540,"elapsed":330,"user":{"displayName":"전성현","userId":"03409279143485008331"}},"outputId":"8a7c2ef6-cfde-4478-d95e-e51ab1f74a7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model(\n","  (linear1): Linear(in_features=1, out_features=3, bias=True)\n","  (linear2): Linear(in_features=3, out_features=5, bias=True)\n","  (linear3): Linear(in_features=5, out_features=5, bias=True)\n","  (linear4): Linear(in_features=5, out_features=1, bias=True)\n","  (relu): ReLU()\n",")\n","tensor([0.3806], grad_fn=<ViewBackward0>)\n"]}],"source":["import torch\n","\n","class Model(torch.nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.linear1 = torch.nn.Linear(1, 3)\n","        self.linear2 = torch.nn.Linear(3, 5)\n","        self.linear3 = torch.nn.Linear(5, 5)\n","        self.linear4 = torch.nn.Linear(5, 1)\n","\n","        self.relu = torch.nn.ReLU()\n","    def forward(self, x):\n","        x = self.relu(self.linear1(x))\n","        x = self.relu(self.linear2(x))\n","        x = self.relu(self.linear3(x))\n","        x = self.linear4(x)\n","        return x\n","\n","model = Model()\n","print(model)\n","\n","x = torch.Tensor([1.0])\n","print(model(x))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RPX4TSaEeD3H"},"source":["### DataLoader가 무엇이고 왜 필요한지 서술하시오"]},{"cell_type":"markdown","metadata":{"id":"yOEojsYbeD3H"},"source":["DataLoader는 데이터 관리를 효율적이고 유연하게 지원하며, 대규모 데이터셋을 다룰 때 매우 유용한 도구입니다. 이를 통해 모델 학습을 간소화하고, 메모리 사용, 데이터 로딩 속도, 데이터 다양성 등을 효과적으로 조절할 수 있습니다. DataLoader는 딥러닝 모델 학습에서 중요한 역할을 합니다."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}